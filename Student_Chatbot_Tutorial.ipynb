{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec62215746104e8abdf1b8dff88d8f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10a28716f5304c56a34e3777c5cd41ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7746e9ae8d946e3abf1b02ca0bb2b0d",
              "IPY_MODEL_4aeb19a9a55249a9bf35796ef31fe84b",
              "IPY_MODEL_ff439654ca9b47818456cc848a84e7d4"
            ]
          }
        },
        "10a28716f5304c56a34e3777c5cd41ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7746e9ae8d946e3abf1b02ca0bb2b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54bdf3328af543ecaa06d87cde880d03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fe0498955d34e139cae58740128bddf"
          }
        },
        "4aeb19a9a55249a9bf35796ef31fe84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14974bb3287b440ab21ad009c46aead0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b96837ca97aa4860bc0571ed31115d61"
          }
        },
        "ff439654ca9b47818456cc848a84e7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58967a9175604d39ac88e6e472733381",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 459B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c2de50339b946139973eb37db5940a0"
          }
        },
        "54bdf3328af543ecaa06d87cde880d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fe0498955d34e139cae58740128bddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14974bb3287b440ab21ad009c46aead0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b96837ca97aa4860bc0571ed31115d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58967a9175604d39ac88e6e472733381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c2de50339b946139973eb37db5940a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50ba0231140d4e42bf024a68e5d66f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_152cbb6bc4f54d22b3f7a34e80405c1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cbe99acea3024dad96b35eb9713b8d79",
              "IPY_MODEL_475a0a46e8384307ba09ecaaefcd2296",
              "IPY_MODEL_9928340701824fa8a674711d0bc10293"
            ]
          }
        },
        "152cbb6bc4f54d22b3f7a34e80405c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbe99acea3024dad96b35eb9713b8d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7178cd0ba7824e36bf9d0cd3ba76c237",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff0ae4af9eea42578ed4a0b0ab70a0bd"
          }
        },
        "475a0a46e8384307ba09ecaaefcd2296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd2a6090ab314867959216b970b1eda2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d1c32eea4a34eda89b9bb291f0d7b4e"
          }
        },
        "9928340701824fa8a674711d0bc10293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67ebec9e72bc47c185bfdbd6290c9191",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 1.37MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc4fb192e98b49179fa658d5332a84c4"
          }
        },
        "7178cd0ba7824e36bf9d0cd3ba76c237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff0ae4af9eea42578ed4a0b0ab70a0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd2a6090ab314867959216b970b1eda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d1c32eea4a34eda89b9bb291f0d7b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67ebec9e72bc47c185bfdbd6290c9191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc4fb192e98b49179fa658d5332a84c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03ef6437ccca4391ae436088678fa2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c7bcf5bf0ab4fbd9445197b20141ee5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae30d4e14357464bb02734979545c471",
              "IPY_MODEL_3eb22f088e1746daacbc1a0356d6477a",
              "IPY_MODEL_59e8b2a470bf4187b0a71949b840faab"
            ]
          }
        },
        "1c7bcf5bf0ab4fbd9445197b20141ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae30d4e14357464bb02734979545c471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6596289625d1498e84bc6d1d8774a541",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e31bc57bacb9451aa6477e5aa1165b63"
          }
        },
        "3eb22f088e1746daacbc1a0356d6477a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5cb76f4b7854c84842f4aeef531d159",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c8e1bc747ec435bb08870275962fb3b"
          }
        },
        "59e8b2a470bf4187b0a71949b840faab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4dfc9205e7b349cdb7371bb5ccc18bad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 8.94kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_898d9c2c090147da8027b488726da1e1"
          }
        },
        "6596289625d1498e84bc6d1d8774a541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e31bc57bacb9451aa6477e5aa1165b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5cb76f4b7854c84842f4aeef531d159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c8e1bc747ec435bb08870275962fb3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dfc9205e7b349cdb7371bb5ccc18bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "898d9c2c090147da8027b488726da1e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afdfe739d00845c2b0676603fd1a51dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_885f68a50bb74f7e88dbab7130b4c1d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1c35f0661194460ab94f34848ae90896",
              "IPY_MODEL_2ac146d96b1e45009f8d30f4e75bb1c6",
              "IPY_MODEL_2b0f28fb32c244eab8588725d8d2edb5"
            ]
          }
        },
        "885f68a50bb74f7e88dbab7130b4c1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c35f0661194460ab94f34848ae90896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bf825a783a94f63b8b835343614ab40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c46e66c752f47f3a58542ac7cc4eb7b"
          }
        },
        "2ac146d96b1e45009f8d30f4e75bb1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eaed9bb257254b1289447fa9940e775a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3258b1e0897a4448926df3b7c5e04cf3"
          }
        },
        "2b0f28fb32c244eab8588725d8d2edb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9d2fbb22d9114a588446ea471e93d143",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 4.84kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_455b0a0845ca47709d91d6696bb6c0ea"
          }
        },
        "7bf825a783a94f63b8b835343614ab40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c46e66c752f47f3a58542ac7cc4eb7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaed9bb257254b1289447fa9940e775a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3258b1e0897a4448926df3b7c5e04cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d2fbb22d9114a588446ea471e93d143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "455b0a0845ca47709d91d6696bb6c0ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e44c4778187f4d97b3265a18482c5ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ca678276cf747ff9dcdd5fbbc28bf54",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43c0a1062b60449684d20f1fe5f95ef8",
              "IPY_MODEL_740ea77c088c46f78a5a45cd7c559346",
              "IPY_MODEL_881f1ecbb1dc478ebe6746119ba0be4a"
            ]
          }
        },
        "7ca678276cf747ff9dcdd5fbbc28bf54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43c0a1062b60449684d20f1fe5f95ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79944d7f17e84c3993211503269f33e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36d42c0f417747f48a5a78e54c085da3"
          }
        },
        "740ea77c088c46f78a5a45cd7c559346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_66ac8a6f55cb4d5dbd86ca8ed9535a58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_579526b8ab52489bbf0d1b06edf1f725"
          }
        },
        "881f1ecbb1dc478ebe6746119ba0be4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5bddf5cb211e467aada8259e251c5863",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:30&lt;00:00, 12.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd94d67b10cc4e52b4b5d2c77bfd8ee6"
          }
        },
        "79944d7f17e84c3993211503269f33e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36d42c0f417747f48a5a78e54c085da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66ac8a6f55cb4d5dbd86ca8ed9535a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "579526b8ab52489bbf0d1b06edf1f725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bddf5cb211e467aada8259e251c5863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd94d67b10cc4e52b4b5d2c77bfd8ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, we will practice different transformer-based techniques to impletement chatbots using Pytorch. \n",
        "\n",
        "Materials are adopted from https://medium.com/geekculture/simple-chatbot-using-bert-and-pytorch-part-1-2735643e0baa."
      ],
      "metadata": {
        "id": "i7iZxY0ss8LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Pytorch:\n",
        "PyTorch is a Python-based scientific computing package that uses the power of graphics processing units(GPU). Since its release in January 2016, many researchers have continued to increasingly adopt PyTorch. It has quickly become a go-to library because of its ease in building extremely complex neural networks. It is giving a tough competition to TensorFlow especially when used for research work.\n",
        "\n",
        "Some of the key highlights of PyTorch includes:\n",
        "\n",
        "**Simple Interface:** It offers easy to use API.\n",
        "\n",
        "**Pythonic in nature:** This library, being Pythonic, smoothly integrates with the Python data science stack.\n",
        "\n",
        "**Tensors:** It is basically the same as a NumPy array. To run operations on the GPU, just cast the Tensor to a Cuda datatype.\n",
        "\n",
        "**Computational graphs:** PyTorch provides an excellent platform that offers dynamic computational graphs.\n",
        "\n",
        "**AUTOGRAD(Automatic Differentiation):** This class is an engine to calculate derivatives."
      ],
      "metadata": {
        "id": "xl7LZGfG50fR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformer:\n",
        "Google introduced the transformer architecture in the paper “Attention is All you need”. The transformer uses a self-attention mechanism, which is suitable for language understanding.\n",
        "Let’s say “I went to the Himalayas this summer. I really enjoyed my time out there”. The last word “there” refers to the Himalayas. But to understand this, remembering the first few parts is essential. To achieve this, the attention mechanism decides at each step of an input sequence which other parts of the sequence are important.\n",
        "The transformer has an encoder-decoder architecture. They are composed of modules that contain feed-forward and attention layers.\n"
      ],
      "metadata": {
        "id": "N7G_0oq52O1Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBv2j019lKi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad36a10-e88c-4b5f-a5f6-6225d9ca1109"
      },
      "source": [
        "!pip install torch\n",
        "# transformers: This library brings together over 40 state-of-the-art pre-trained NLP models (BERT, GPT-2, Roberta, etc..)\n",
        "!pip install transformers\n",
        "# To print the model architecture.\n",
        "!pip install torchinfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 31.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import matplotlib.pyplot as plt\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "EZjvcnohBeR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BERT (Bidirectional Encoder Representations from Transformers):\n",
        "First, we will build a chatbot using BERT, a transformer-based model that only adopts the encoder component. It is a transformer-based machine learning technique for natural language processing pre-training developed by Google. BERT was created and published in 2018 by Jacob Devlin and his colleagues from Google.\n",
        "BERT uses bidirectional training i.e it reads the sentence from both directions to understand the context of the sentence.\n",
        "Note that BERT is just an encoder. It does not have a decoder."
      ],
      "metadata": {
        "id": "m3uHYqo87YKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Data\n",
        "As a first step, we need to set up an intents JSON file that defines the intentions of the chatbot user.\n",
        "For example:\n",
        "A user may wish to know the name of our chatbot; therefore, we have created an intent called name.\n",
        "In this chatbot, we have used 5 intents: name, help, hobby, greeting, and goodbye. We have used the training set that has utterances belonging to each of these intents. When the user enters any input, the intent will be recognized by the bot.\n",
        "Within this intents JSON file, alongside each intents tag, there are responses. For our chatbot, once the intent is recognized the response will be randomly selected from the static set of responses associated with each intent."
      ],
      "metadata": {
        "id": "fL-IKTST8giQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# used a dictionary to represent an intents JSON file\n",
        "intents = {\"intents\": [\n",
        "{\"tag\": \"greeting\",\n",
        " \"responses\": [\"Howdy Partner!\", \"Hello\", \"How are you doing?\",   \"Greetings!\", \"How do you do?\"]},\n",
        "{\"tag\": \"hobby\",\n",
        " \"responses\": [\"I'm working on it.\", \"I should get one. It's all work and no play lately.\"]},\n",
        "{\"tag\": \"help\",\n",
        " \"responses\": [\"Sure. I'd be happy to. What's up?\", \"I'm glad to help. What can I do for you?\"]},\n",
        "{\"tag\": \"name\",\n",
        " \"responses\": [\"My name is James\", \"I'm James\", \"James\"]},\n",
        "{\"tag\": \"goodbye\",\n",
        " \"responses\": [\"It was nice speaking to you\", \"See you later\", \"Speak soon!\"]}\n",
        "]}"
      ],
      "metadata": {
        "id": "yX4XrFaC_h3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We have prepared a intent dataset with 5 labels, download training file\n",
        "!wget https://raw.github.com/JinfenLi/teaching_material/master/chatbot_intent.xlsx\n"
      ],
      "metadata": {
        "id": "soNBV7pm-0P6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f806ffb-4833-428e-c9b0-84114470e697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-07 00:28:51--  https://raw.github.com/JinfenLi/teaching_material/master/chatbot_intent.xlsx\n",
            "Resolving raw.github.com (raw.github.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.github.com (raw.github.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/JinfenLi/teaching_material/master/chatbot_intent.xlsx [following]\n",
            "--2022-03-07 00:28:51--  https://raw.githubusercontent.com/JinfenLi/teaching_material/master/chatbot_intent.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13171 (13K) [application/octet-stream]\n",
            "Saving to: ‘chatbot_intent.xlsx’\n",
            "\n",
            "chatbot_intent.xlsx 100%[===================>]  12.86K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-07 00:28:51 (61.8 MB/s) - ‘chatbot_intent.xlsx’ saved [13171/13171]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_excel(\"chatbot_intent.xlsx\")\n",
        "print(df.head())\n",
        "df[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "PtOaALi5Bxvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5483d19a-ed1a-48ca-e94b-dfda46b58cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                text    label\n",
            "0              BBIAB  goodbye\n",
            "1    I got to go now  goodbye\n",
            "2         I gotta go  goodbye\n",
            "3       I'll be back  goodbye\n",
            "4  I'll be back soon  goodbye\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "goodbye     81\n",
              "greeting    43\n",
              "help        34\n",
              "name        10\n",
              "hobby        7\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the labels into encodings\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['label'])\n",
        "df['label']"
      ],
      "metadata": {
        "id": "Q-UyNdLy0evb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1b63f4-aee5-41f4-82f3-e136c7956edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "170    3\n",
              "171    3\n",
              "172    3\n",
              "173    3\n",
              "174    3\n",
              "Name: label, Length: 175, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example we have used all the utterances for training purpose\n",
        "train_text, train_labels = df['text'], df['label']"
      ],
      "metadata": {
        "id": "EsteoxYMKyBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Preparation\n",
        "We will build Bert-base-uncased as an example and leave Roberta-base model to you."
      ],
      "metadata": {
        "id": "p6wlQmb6LI8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, BertTokenizerFast\n",
        "# Load the BERT tokenizer\n",
        "bert_tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "# Import BERT-base pretrained model\n",
        "bert_model = AutoModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "F_-tgHzZM_PA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250,
          "referenced_widgets": [
            "ec62215746104e8abdf1b8dff88d8f9a",
            "10a28716f5304c56a34e3777c5cd41ed",
            "f7746e9ae8d946e3abf1b02ca0bb2b0d",
            "4aeb19a9a55249a9bf35796ef31fe84b",
            "ff439654ca9b47818456cc848a84e7d4",
            "54bdf3328af543ecaa06d87cde880d03",
            "8fe0498955d34e139cae58740128bddf",
            "14974bb3287b440ab21ad009c46aead0",
            "b96837ca97aa4860bc0571ed31115d61",
            "58967a9175604d39ac88e6e472733381",
            "7c2de50339b946139973eb37db5940a0",
            "50ba0231140d4e42bf024a68e5d66f93",
            "152cbb6bc4f54d22b3f7a34e80405c1c",
            "cbe99acea3024dad96b35eb9713b8d79",
            "475a0a46e8384307ba09ecaaefcd2296",
            "9928340701824fa8a674711d0bc10293",
            "7178cd0ba7824e36bf9d0cd3ba76c237",
            "ff0ae4af9eea42578ed4a0b0ab70a0bd",
            "cd2a6090ab314867959216b970b1eda2",
            "7d1c32eea4a34eda89b9bb291f0d7b4e",
            "67ebec9e72bc47c185bfdbd6290c9191",
            "fc4fb192e98b49179fa658d5332a84c4",
            "03ef6437ccca4391ae436088678fa2fc",
            "1c7bcf5bf0ab4fbd9445197b20141ee5",
            "ae30d4e14357464bb02734979545c471",
            "3eb22f088e1746daacbc1a0356d6477a",
            "59e8b2a470bf4187b0a71949b840faab",
            "6596289625d1498e84bc6d1d8774a541",
            "e31bc57bacb9451aa6477e5aa1165b63",
            "f5cb76f4b7854c84842f4aeef531d159",
            "0c8e1bc747ec435bb08870275962fb3b",
            "4dfc9205e7b349cdb7371bb5ccc18bad",
            "898d9c2c090147da8027b488726da1e1",
            "afdfe739d00845c2b0676603fd1a51dd",
            "885f68a50bb74f7e88dbab7130b4c1d0",
            "1c35f0661194460ab94f34848ae90896",
            "2ac146d96b1e45009f8d30f4e75bb1c6",
            "2b0f28fb32c244eab8588725d8d2edb5",
            "7bf825a783a94f63b8b835343614ab40",
            "4c46e66c752f47f3a58542ac7cc4eb7b",
            "eaed9bb257254b1289447fa9940e775a",
            "3258b1e0897a4448926df3b7c5e04cf3",
            "9d2fbb22d9114a588446ea471e93d143",
            "455b0a0845ca47709d91d6696bb6c0ea",
            "e44c4778187f4d97b3265a18482c5ef6",
            "7ca678276cf747ff9dcdd5fbbc28bf54",
            "43c0a1062b60449684d20f1fe5f95ef8",
            "740ea77c088c46f78a5a45cd7c559346",
            "881f1ecbb1dc478ebe6746119ba0be4a",
            "79944d7f17e84c3993211503269f33e4",
            "36d42c0f417747f48a5a78e54c085da3",
            "66ac8a6f55cb4d5dbd86ca8ed9535a58",
            "579526b8ab52489bbf0d1b06edf1f725",
            "5bddf5cb211e467aada8259e251c5863",
            "dd94d67b10cc4e52b4b5d2c77bfd8ee6"
          ]
        },
        "outputId": "dc5b2fa9-8673-4265-daa2-b237e3ded81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec62215746104e8abdf1b8dff88d8f9a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50ba0231140d4e42bf024a68e5d66f93",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03ef6437ccca4391ae436088678fa2fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afdfe739d00845c2b0676603fd1a51dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e44c4778187f4d97b3265a18482c5ef6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data for BERT tokenizer\n",
        "text = [\"this is a distil bert model.\",\"data is oil\"]\n",
        "# Encode the text, padding if text length < maximum length and truncation otherwise\n",
        "encoded_input = bert_tokenizer(text, padding=True,truncation=True, return_tensors='pt')\n",
        "\"\"\"\n",
        "In input_ids:\n",
        "101 - Indicates beginning of the sentence\n",
        "102 - Indicates end of the sentence\n",
        "In token_type_ids:\n",
        "0 - first part of the text\n",
        "1 - second part of the text\n",
        "In attention_mask:\n",
        "1 - Actual token\n",
        "0 - Padded token\n",
        "\"\"\"\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "id": "1sBYebZIOhPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909c62a5-a826-49f2-fce5-9146817006e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2023,  2003,  1037,  4487, 16643,  2140, 14324,  2944,  1012,\n",
            "           102],\n",
            "        [  101,  2951,  2003,  3514,   102,     0,     0,     0,     0,     0,\n",
            "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "# choose the max length from seq_len. Note: the max length should not exceed the corresponding configuration in the model (e.g., 256 for bert-base-uncased model)\n",
        "bert_max_seq_len = max(seq_len)\n",
        "bert_max_seq_len"
      ],
      "metadata": {
        "id": "Tu1cUzYlQF23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fdc741-d3fb-46e3-c211-6a1dbdd65af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "bert_tokens_train = bert_tokenizer(\n",
        "    train_text.tolist(),\n",
        "    max_length = bert_max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "bert_tokens_train"
      ],
      "metadata": {
        "id": "7IWq1TjJREM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b666ca0a-224f-4081-d969-b5639dc65f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 22861, 2401, 2497, 102, 0, 0, 0], [101, 1045, 2288, 2000, 2175, 2085, 102, 0], [101, 1045, 10657, 2175, 102, 0, 0, 0], [101, 1045, 1005, 2222, 2022, 2067, 102, 0], [101, 1045, 1005, 2222, 2022, 2067, 2574, 102], [101, 1045, 1005, 2222, 2131, 2067, 2000, 102], [101, 1045, 1005, 2222, 3335, 2017, 102, 0], [101, 2009, 1005, 1055, 2042, 3835, 2000, 102], [101, 27133, 2891, 102, 0, 0, 0, 0], [101, 10303, 9061, 102, 0, 0, 0, 0], [101, 10303, 2204, 2305, 102, 0, 0, 0], [101, 9120, 1996, 11834, 102, 0, 0, 0], [101, 2004, 2696, 2474, 13005, 102, 0, 0], [101, 2067, 1999, 1037, 2978, 102, 0, 0], [101, 2022, 2067, 1999, 1019, 2781, 102, 0], [101, 2022, 2067, 1999, 1037, 2261, 102, 0], [101, 9061, 102, 0, 0, 0, 0, 0], [101, 9061, 9061, 102, 0, 0, 0, 0], [101, 9061, 9061, 2156, 2017, 102, 0, 0], [101, 9061, 9061, 2156, 2017, 2574, 102, 0], [101, 9061, 9061, 2202, 2729, 102, 0, 0], [101, 9061, 2005, 2085, 102, 0, 0, 0], [101, 9061, 2204, 2305, 102, 0, 0, 0], [101, 9061, 1011, 9061, 102, 0, 0, 0], [101, 11834, 2101, 102, 0, 0, 0, 0], [101, 15138, 3695, 102, 0, 0, 0, 0], [101, 21250, 102, 0, 0, 0, 0, 0], [101, 9915, 2080, 102, 0, 0, 0, 0], [101, 2986, 2005, 2085, 102, 0, 0, 0], [101, 2131, 2439, 102, 0, 0, 0, 0], [101, 2175, 2000, 2793, 102, 0, 0, 0], [101, 2183, 2000, 2793, 102, 0, 0, 0], [101, 2183, 2000, 2793, 2085, 102, 0, 0], [101, 2204, 9061, 102, 0, 0, 0, 0], [101, 2204, 2305, 102, 0, 0, 0, 0], [101, 2204, 2305, 9061, 102, 0, 0, 0], [101, 2204, 2305, 2000, 2017, 102, 0, 0], [101, 2204, 3331, 2000, 2017, 102, 0, 0], [101, 2204, 2000, 11834, 102, 0, 0, 0], [101, 9119, 102, 0, 0, 0, 0, 0], [101, 9119, 2005, 2085, 102, 0, 0, 0], [101, 9119, 2156, 2017, 2101, 102, 0, 0], [101, 22708, 2085, 102, 0, 0, 0, 0], [101, 2288, 2131, 3637, 102, 0, 0, 0], [101, 10657, 2175, 2000, 3637, 102, 0, 0], [101, 2031, 1037, 2204, 2305, 102, 0, 0], [101, 3246, 2000, 2156, 2017, 2101, 102, 0], [101, 2009, 1005, 1055, 2793, 2051, 102, 0], [101, 2009, 1005, 1055, 2042, 1037, 5165, 102], [101, 2101, 2017, 102, 0, 0, 0, 0], [101, 2681, 2033, 2894, 102, 0, 0, 0], [101, 3835, 3331, 2000, 2017, 102, 0, 0], [101, 3835, 2000, 11834, 102, 0, 0, 0], [101, 3835, 2000, 2831, 2000, 2017, 102, 0], [101, 7929, 9061, 102, 0, 0, 0, 0], [101, 7929, 2031, 1037, 2204, 2305, 102, 0], [101, 3100, 9061, 102, 0, 0, 0, 0], [101, 3100, 2156, 2017, 2101, 102, 0, 0], [101, 3100, 4067, 2017, 9061, 102, 0, 0], [101, 2360, 7856, 2527, 102, 0, 0, 0], [101, 2156, 8038, 102, 0, 0, 0, 0], [101, 2156, 2017, 102, 0, 0, 0, 0], [101, 2156, 2017, 2574, 102, 0, 0, 0], [101, 2156, 2017, 4826, 102, 0, 0, 0], [101, 3713, 2000, 8038, 102, 0, 0, 0], [101, 4086, 5544, 102, 0, 0, 0, 0], [101, 11937, 11937, 2005, 2085, 102, 0, 0], [101, 2202, 2729, 102, 0, 0, 0, 0], [101, 2202, 2009, 3733, 102, 0, 0, 0], [101, 2831, 2000, 2017, 2101, 102, 0, 0], [101, 4283, 9061, 102, 0, 0, 0, 0], [101, 4283, 9061, 9061, 102, 0, 0, 0], [101, 4283, 2005, 22331, 102, 0, 0, 0], [101, 4283, 2204, 2305, 102, 0, 0, 0], [101, 2008, 1005, 1055, 2035, 2005, 2085, 102], [101, 18681, 2279, 2051, 102, 0, 0, 0], [101, 18681, 2057, 3113, 2153, 102, 0, 0], [101, 6229, 2279, 2051, 102, 0, 0, 0], [101, 2051, 2000, 2175, 102, 0, 0, 0], [101, 2051, 2000, 2175, 2000, 2793, 102, 0], [101, 2017, 2064, 2175, 2085, 102, 0, 0], [101, 3835, 2000, 3113, 2017, 102, 0, 0], [101, 2009, 2001, 3835, 3116, 2017, 102, 0], [101, 2009, 2001, 2200, 3835, 2000, 3113, 102], [101, 2204, 2000, 2113, 2169, 2060, 102, 0], [101, 5580, 2000, 3113, 2017, 102, 0, 0], [101, 3835, 3116, 2017, 102, 0, 0, 0], [101, 3835, 2000, 3113, 2017, 2205, 102, 0], [101, 7537, 2000, 3113, 2017, 102, 0, 0], [101, 5165, 2000, 3113, 2017, 102, 0, 0], [101, 5165, 2000, 3113, 2017, 2205, 102, 0], [101, 2009, 1005, 1055, 3835, 2000, 2156, 102], [101, 8403, 2000, 2156, 2017, 102, 0, 0], [101, 1045, 1005, 1049, 5580, 2000, 2156, 102], [101, 2307, 2000, 2156, 2017, 102, 0, 0], [101, 2009, 1005, 1055, 2204, 2000, 2156, 102], [101, 5580, 2000, 2156, 2017, 102, 0, 0], [101, 2129, 2204, 2009, 2003, 2000, 2156, 102], [101, 2467, 1037, 5165, 2000, 2156, 2017, 102], [101, 3835, 2000, 2156, 2017, 102, 0, 0], [101, 2204, 2000, 2156, 2017, 102, 0, 0], [101, 2307, 2000, 2156, 2017, 2153, 102, 0], [101, 2307, 2000, 2156, 2017, 2205, 102, 0], [101, 1045, 2572, 5580, 2000, 2156, 2017, 102], [101, 3835, 2000, 2156, 2017, 2153, 102, 0], [101, 5580, 2000, 2156, 2017, 2205, 102, 0], [101, 2204, 2000, 2156, 2017, 2153, 102, 0], [101, 2009, 1005, 1055, 2204, 2000, 2156, 102], [101, 2054, 2003, 2006, 2115, 2568, 102, 0], [101, 2054, 1005, 1055, 3047, 102, 0, 0], [101, 2054, 2003, 2039, 102, 0, 0, 0], [101, 2054, 1005, 1055, 2039, 102, 0, 0], [101, 1059, 3270, 13213, 6279, 102, 0, 0], [101, 2204, 2054, 1005, 1055, 2039, 102, 0], [101, 1045, 2056, 2054, 1005, 1055, 2039, 102], [101, 2059, 2054, 1005, 1055, 2039, 102, 0], [101, 2054, 1005, 1055, 5513, 102, 0, 0], [101, 2001, 6342, 2361, 102, 0, 0, 0], [101, 2054, 2003, 2183, 2006, 102, 0, 0], [101, 2054, 2003, 6230, 102, 0, 0, 0], [101, 2054, 1005, 1055, 15729, 102, 0, 0], [101, 2054, 1005, 1055, 8434, 102, 0, 0], [101, 4931, 2054, 1005, 1055, 2039, 102, 0], [101, 2054, 1005, 1055, 2039, 2651, 102, 0], [101, 2040, 2024, 2017, 1029, 102, 0, 0], [101, 2054, 22320, 10930, 2171, 1029, 102, 0], [101, 2171, 1029, 102, 0, 0, 0, 0], [101, 2054, 2079, 2111, 2655, 2017, 1029, 102], [101, 2054, 2003, 2115, 2171, 1029, 102, 0], [101, 2115, 2171, 1029, 102, 0, 0, 0], [101, 15125, 102, 0, 0, 0, 0, 0], [101, 2171, 102, 0, 0, 0, 0, 0], [101, 2079, 2017, 2031, 1037, 2171, 1029, 102], [101, 2054, 2003, 2115, 2171, 1029, 102, 0], [101, 1045, 2342, 1037, 2192, 102, 0, 0], [101, 1045, 2342, 2393, 102, 0, 0, 0], [101, 1045, 2342, 2070, 2393, 102, 0, 0], [101, 1045, 2342, 2017, 2393, 2033, 2085, 102], [101, 1045, 2342, 2017, 2157, 2085, 102, 0], [101, 1045, 2342, 2017, 2000, 2079, 2242, 102], [101, 1045, 2342, 2017, 2000, 2393, 2033, 102], [101, 1045, 2342, 2115, 2393, 102, 0, 0], [101, 1045, 2215, 2115, 2393, 102, 0, 0], [101, 2024, 2017, 2183, 2000, 2393, 2033, 102], [101, 6509, 102, 0, 0, 0, 0, 0], [101, 6509, 2033, 102, 0, 0, 0, 0], [101, 5375, 102, 0, 0, 0, 0, 0], [101, 2064, 2393, 2033, 102, 0, 0, 0], [101, 2064, 1057, 2393, 2033, 102, 0, 0], [101, 2064, 2017, 6509, 2033, 102, 0, 0], [101, 2071, 2017, 2507, 2033, 1037, 2192, 102], [101, 2079, 2033, 1037, 5684, 102, 0, 0], [101, 2079, 2017, 2393, 2033, 102, 0, 0], [101, 2079, 2017, 2215, 2000, 2393, 2033, 102], [101, 2393, 102, 0, 0, 0, 0, 0], [101, 2393, 2033, 102, 0, 0, 0, 0], [101, 2393, 2033, 2041, 102, 0, 0, 0], [101, 2393, 2033, 2007, 1037, 3291, 102, 0], [101, 2393, 2033, 2007, 2008, 102, 0, 0], [101, 2393, 2149, 102, 0, 0, 0, 0], [101, 2342, 2393, 102, 0, 0, 0, 0], [101, 2342, 2115, 2393, 102, 0, 0, 0], [101, 3531, 2393, 2033, 102, 0, 0, 0], [101, 2061, 2015, 102, 0, 0, 0, 0], [101, 2097, 2017, 2393, 2033, 102, 0, 0], [101, 2052, 2017, 2393, 2033, 102, 0, 0], [101, 2017, 2064, 2393, 2033, 2393, 2033, 102], [101, 2017, 2393, 2033, 102, 0, 0, 0], [101, 2054, 2079, 2017, 2079, 2005, 4569, 102], [101, 2054, 1005, 1055, 2115, 17792, 102, 0], [101, 2425, 2033, 2055, 2115, 17792, 102, 0], [101, 2079, 2017, 2031, 1037, 17792, 102, 0], [101, 2054, 2055, 2115, 17792, 102, 0, 0], [101, 2115, 17792, 102, 0, 0, 0, 0], [101, 2054, 2024, 2115, 7570, 27982, 102, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the integer sequences to tensors\n",
        "bert_train_seq = torch.tensor(bert_tokens_train['input_ids'])\n",
        "bert_train_mask = torch.tensor(bert_tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())"
      ],
      "metadata": {
        "id": "bUxx2-fDRY9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "#define a batch size\n",
        "batch_size = 16\n",
        "# wrap tensors\n",
        "bert_train_data = TensorDataset(bert_train_seq, bert_train_mask, train_y)\n",
        "# sampler for sampling the data during training\n",
        "bert_train_sampler = RandomSampler(bert_train_data)\n",
        "# DataLoader for train set\n",
        "bert_train_dataloader = DataLoader(bert_train_data, sampler=bert_train_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "mmjmxr1vRueN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a model for intent classification (sequence classification)\n",
        "class BERT_Arch(nn.Module):\n",
        "   def __init__(self, bert):      \n",
        "       super(BERT_Arch, self).__init__()\n",
        "       self.bert = bert \n",
        "      \n",
        "       # dropout layer\n",
        "       self.dropout = nn.Dropout(0.2)\n",
        "      \n",
        "       # relu activation function\n",
        "       self.relu =  nn.ReLU()\n",
        "       # dense layer\n",
        "       self.fc1 = nn.Linear(768,512)\n",
        "       self.fc2 = nn.Linear(512,256)\n",
        "       self.fc3 = nn.Linear(256,5)\n",
        "       #softmax activation function\n",
        "       self.softmax = nn.LogSoftmax(dim=1)\n",
        "       #define the forward pass\n",
        "   def forward(self, sent_id, mask):\n",
        "      #pass the inputs to the model  \n",
        "      cls_hs = self.bert(sent_id, attention_mask=mask)[0][:,0]\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      \n",
        "      x = self.fc2(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      # output layer\n",
        "      x = self.fc3(x)\n",
        "   \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "fINVnDIoUV6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters. This will prevent updating of model weights during fine-tuning.\n",
        "for param in bert_model.parameters():\n",
        "      param.requires_grad = False\n",
        "bert_seq_model = BERT_Arch(bert_model)\n",
        "# push the model to GPU if GPU is available, otherwise CPU\n",
        "bert_seq_model = bert_seq_model.to(device)\n",
        "from torchinfo import summary\n",
        "summary(bert_seq_model)"
      ],
      "metadata": {
        "id": "5aikj6MlUwTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954260ad-5539-4509-ff70-eff818457fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "BERT_Arch                                               --\n",
              "├─BertModel: 1-1                                        --\n",
              "│    └─BertEmbeddings: 2-1                              --\n",
              "│    │    └─Embedding: 3-1                              (23,440,896)\n",
              "│    │    └─Embedding: 3-2                              (393,216)\n",
              "│    │    └─Embedding: 3-3                              (1,536)\n",
              "│    │    └─LayerNorm: 3-4                              (1,536)\n",
              "│    │    └─Dropout: 3-5                                --\n",
              "│    └─BertEncoder: 2-2                                 --\n",
              "│    │    └─ModuleList: 3-6                             (85,054,464)\n",
              "│    └─BertPooler: 2-3                                  --\n",
              "│    │    └─Linear: 3-7                                 (590,592)\n",
              "│    │    └─Tanh: 3-8                                   --\n",
              "├─Dropout: 1-2                                          --\n",
              "├─ReLU: 1-3                                             --\n",
              "├─Linear: 1-4                                           393,728\n",
              "├─Linear: 1-5                                           131,328\n",
              "├─Linear: 1-6                                           1,285\n",
              "├─LogSoftmax: 1-7                                       --\n",
              "================================================================================\n",
              "Total params: 110,008,581\n",
              "Trainable params: 526,341\n",
              "Non-trainable params: 109,482,240\n",
              "================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Finetune Model\n",
        "Optimizer\n",
        "Using the Optimizer we reduce the loss during backpropagation through the network."
      ],
      "metadata": {
        "id": "fb3S2jY3Vn1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Optimizer\n",
        "Using the Optimizer we reduce the loss during backpropagation through the network."
      ],
      "metadata": {
        "id": "OGlpTrB4WAPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "# define the optimizer\n",
        "bert_optimizer = AdamW(bert_seq_model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "NBd_NC6PWK96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cda54e-cf30-4a9a-9701-5929e4e690af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Find Class Weights"
      ],
      "metadata": {
        "id": "bPK5tPHrWYY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_labels),\n",
        "                                        y = train_labels                                                    \n",
        "                                    )\n",
        "class_wts"
      ],
      "metadata": {
        "id": "1pe1YVzwWcBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67255cd-42c0-4928-dd3d-cc18943e6609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.43209877, 0.81395349, 1.02941176, 5.        , 3.5       ])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Balancing the weights while calculating the error"
      ],
      "metadata": {
        "id": "XeQllKkUXSER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "# loss function\n",
        "cross_entropy = nn.NLLLoss(weight=weights) "
      ],
      "metadata": {
        "id": "u6YthmPCXTtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting up the epochs"
      ],
      "metadata": {
        "id": "9hEzdDBjXlFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import lr_scheduler\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "bert_train_losses=[]\n",
        "# number of training epochs\n",
        "epochs = 10\n",
        "# We can also use learning rate scheduler to achieve better results\n",
        "bert_lr_sch = lr_scheduler.StepLR(bert_optimizer, step_size=100, gamma=0.1)"
      ],
      "metadata": {
        "id": "ncf-92svXn3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fine-Tune the model"
      ],
      "metadata": {
        "id": "UV-X-A-oYN17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train(model, train_dataloader, optimizer, lr_sch):\n",
        "  \n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch] \n",
        "    sent_id, mask, labels = batch\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "    print(loss)\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "    # clip the the gradients to 1.0. It helps in preventing the    exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    # clear calculated gradients\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    # We are using learning rate scheduler\n",
        "    # lr_sch.step()\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(bert_train_dataloader)\n",
        "    \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "X8CSAXBmYRMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Start Model Training"
      ],
      "metadata": {
        "id": "J3_TX79nYfc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train(bert_seq_model, bert_train_dataloader, bert_optimizer, bert_lr_sch)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    bert_train_losses.append(train_loss)\n",
        "    # it can make your experiment reproducible, similar to set  random seed to all options where there needs a random seed.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "print(f'\\nTraining Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "id": "QktMk5quYijr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376513e4-efc4-40c0-a7cc-c7cd44357f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "tensor(1.6242, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6601, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5640, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5766, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5053, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4827, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3986, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6557, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0035, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9824, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2658, grad_fn=<NllLossBackward0>)\n",
            "\n",
            " Epoch 2 / 10\n",
            "tensor(1.5280, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6509, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2097, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4314, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3516, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4837, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2350, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2988, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2348, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2569, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1698, grad_fn=<NllLossBackward0>)\n",
            "\n",
            " Epoch 3 / 10\n",
            "tensor(1.0128, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8231, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3675, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3249, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0363, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1278, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7905, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6011, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1780, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5692, grad_fn=<NllLossBackward0>)\n",
            "\n",
            " Epoch 4 / 10\n",
            "tensor(0.5204, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5640, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9641, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4785, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4104, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0594, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4028, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7292, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6501, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8925, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9983, grad_fn=<NllLossBackward0>)\n",
            "\n",
            " Epoch 5 / 10\n",
            "tensor(0.3211, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5915, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2954, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4698, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1290, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6483, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3285, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3414, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5169, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9636, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4151, grad_fn=<NllLossBackward0>)\n",
            "\n",
            " Epoch 6 / 10\n",
            "tensor(0.3466, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5194, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3233, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2398, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7030, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2551, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4276, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4466, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5529, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2595, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4401, grad_fn=<NllLossBackward0>)\n",
            "\n",
            " Epoch 7 / 10\n",
            "tensor(0.3373, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4435, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2819, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1971, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0979, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3443, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3066, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4071, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1530, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3250, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1010, grad_fn=<NllLossBackward0>)\n",
            "\n",
            " Epoch 8 / 10\n",
            "tensor(0.3861, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2000, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2612, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3261, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2214, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4691, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2130, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0749, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3139, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7515, grad_fn=<NllLossBackward0>)\n",
            "\n",
            " Epoch 9 / 10\n",
            "tensor(0.4487, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0980, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5033, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2294, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0982, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0415, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2417, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3522, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0765, grad_fn=<NllLossBackward0>)\n",
            "\n",
            " Epoch 10 / 10\n",
            "tensor(0.2104, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0671, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2339, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0853, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0508, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0863, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0479, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0482, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0903, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1340, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Training Loss: 0.100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Get Predictions for Test Data"
      ],
      "metadata": {
        "id": "F9c2qE6bYl-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(str, model, tokenizer, max_seq_len):\n",
        "  str = re.sub(r'[^a-zA-Z ]+', '', str)\n",
        "  test_text = [str]\n",
        "  model.eval()\n",
        "\n",
        "  tokens_test_data = tokenizer(\n",
        "  test_text,\n",
        "  max_length = max_seq_len,\n",
        "  pad_to_max_length=True,\n",
        "  truncation=True,\n",
        "  return_token_type_ids=False\n",
        "  )\n",
        "  test_seq = torch.tensor(tokens_test_data['input_ids'])\n",
        "  test_mask = torch.tensor(tokens_test_data['attention_mask'])\n",
        "\n",
        "  preds = None\n",
        "  with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "  print(\"Intent Identified: \", le.inverse_transform(preds)[0])\n",
        "  return le.inverse_transform(preds)[0]\n",
        "def get_response(message, model, tokenizer, max_seq_len): \n",
        "  intent = get_prediction(message, model, tokenizer, max_seq_len)\n",
        "  for i in intents['intents']: \n",
        "    if i[\"tag\"] == intent:\n",
        "      result = random.choice(i[\"responses\"])\n",
        "      break\n",
        "  print(f\"Response : {result}\")\n",
        "  return \"Intent: \"+ intent + '\\n' + \"Response: \" + result"
      ],
      "metadata": {
        "id": "tosbHFGGYtup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let's test the model now:"
      ],
      "metadata": {
        "id": "TzApw7RTY6p_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_response(\"why dont you introduce yourself\", bert_seq_model, bert_tokenizer, bert_max_seq_len)"
      ],
      "metadata": {
        "id": "eSedMd4YY9AR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "8d11a4f6-f5d0-412f-f081-3861409e8217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent Identified:  name\n",
            "Response : I'm James\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Intent: name\\nResponse: I'm James\""
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Your Hands Dirty!\n",
        "Now, it is your turn to build the Roberta-base model."
      ],
      "metadata": {
        "id": "UAz8iLIBN3YQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Roberta\n",
        "RoBERTa is part of Facebook’s ongoing commitment to advancing the state-of-the-art in self-supervised systems that can be developed with less reliance on time- and resource-intensive data labeling.\n",
        "The authors of RoBERTa suggest that BERT is largely undertrained and hence, they put forth the following improvements for the same.\n",
        "*   More training data (16G vs 160G)\n",
        "*   Uses dynamic masking pattern instead of static masking pattern.\n",
        "*   Replacing the next sentence prediction objective with full sentences without NSP.\n",
        "*   Training on Longer Sequences.\n",
        "\n",
        "Aopted from https://medium.com/analytics-vidhya/evolving-with-bert-introduction-to-roberta-5174ec0e7c82.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EBwrUv0-rYOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the Roberta model and Roberta tokenizer\n",
        "roberta_model = \n",
        "roberta_tokenizer = "
      ],
      "metadata": {
        "id": "WtKQ6cbZrN5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "8f3df0d0-e57c-4bf1-961a-11ffbbf046ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-080c97d0802f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    roberta_model =\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# there is a sequence classification pretrained model that you don't need to implement your own BERT_Arch\n",
        "# import that sequence classification model here\n",
        "roberta_seq_model = \n",
        "# push the model to GPU if GPU is available, otherwise CPU\n",
        "roberta_seq_model = \n"
      ],
      "metadata": {
        "id": "wCgKTmmdUfCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the train_text, try to set max_seq_len as 20 this time\n",
        "roberta_max_seq_len = \n",
        "roberta_tokens_train = "
      ],
      "metadata": {
        "id": "eU4kwp0DtqrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the integer sequences to tensors.\n",
        "roberta_train_seq = \n",
        "roberta_train_mask = "
      ],
      "metadata": {
        "id": "f6kccXLMu9C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, try to create dataloaders for the train_data and use sequential sampler this time\n",
        "from torch.utils.data import SequentialSampler\n",
        "#define a batch size\n",
        "batch_size = 16\n",
        "# wrap tensors\n",
        "roberta_train_data = \n",
        "# sampler for sampling the data during training\n",
        "roberta_train_sampler = \n",
        "# DataLoader for train set\n",
        "roberta_train_dataloader = "
      ],
      "metadata": {
        "id": "e0GAzHkRwYjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the differences between RandomSampler and SequentialSampler? Please provide your rationale here."
      ],
      "metadata": {
        "id": "LEvctGaWy6ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rationale = input()"
      ],
      "metadata": {
        "id": "bmOPyGbFDvTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try to use Adafactor and AdafactorSchedule this time\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "roberta_optimizer = \n",
        "roberta_lr_sch = "
      ],
      "metadata": {
        "id": "d1WwZjx91BGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty lists to store training and validation loss of each epoch\n",
        "roberta_train_losses = []\n",
        "# number of training epochs\n",
        "roberta_epochs = 10"
      ],
      "metadata": {
        "id": "xiLU7-nl3H0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start Roberta model training\n",
        "for epoch in range(roberta_epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, roberta_epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = \n",
        "    \n",
        "    # append training and validation loss\n",
        "    roberta_train_losses.append(train_loss)\n",
        "    # it can make your experiment reproducible, similar to set  random seed to all options where there needs a random seed.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "print(f'\\nTraining Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "id": "tgWxYub_3_v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Predictions for Test Data\n",
        "get_response(\"Goodbye\", roberta_seq_model, roberta_tokenizer, roberta_max_seq_len)"
      ],
      "metadata": {
        "id": "tetiE1OQOf0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPT-2. \n",
        "GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences. Please check\n",
        "https://huggingface.co/gpt2?text=A+long+time+ago%2C for more."
      ],
      "metadata": {
        "id": "Nub82LzB2Y3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will implement a GPT-2 chatbot using the previous coding style."
      ],
      "metadata": {
        "id": "eCjs_2-frgSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "# select a token to use as `pad_token`\n",
        "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
        "gpt_model = GPT2Model.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "UOwXcMeu2cqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build sequence classification model here\n",
        "gpt_seq_model = BERT_Arch(gpt_model)\n",
        "# push the model to GPU if GPU is available, otherwise CPU\n",
        "gpt_seq_model = gpt_seq_model.to(device)"
      ],
      "metadata": {
        "id": "rgNhfN4fUaOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Replace me by any text you'd like.\"\n",
        "# Encode the text\n",
        "gpt_encoded_input = gpt_tokenizer(text, padding=True,truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "l52EloRLVX0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the train_text, try to set max_seq_len as 10 this time\n",
        "gpt_max_seq_len = 10\n",
        "gpt_tokenizer\n",
        "gpt_tokens_train = gpt_tokenizer(\n",
        "    train_text.tolist(),\n",
        "    max_length = gpt_max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "id": "pE_EPX-YVn-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the integer sequences to tensors.\n",
        "gpt_train_seq = torch.tensor(gpt_tokens_train['input_ids'])\n",
        "gpt_train_mask = torch.tensor(gpt_tokens_train['attention_mask'])"
      ],
      "metadata": {
        "id": "oMnpOCAkRRnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloader\n",
        "#define a batch size\n",
        "batch_size = 16\n",
        "# wrap tensors\n",
        "gpt_train_data = TensorDataset(gpt_train_seq, gpt_train_mask, train_y)\n",
        "# sampler for sampling the data during training\n",
        "gpt_train_sampler = RandomSampler(gpt_train_data)\n",
        "# DataLoader for train set\n",
        "gpt_train_dataloader = DataLoader(gpt_train_data, sampler=gpt_train_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "n_wBfpsfRdQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a optimizer\n",
        "gpt_optimizer = AdamW(gpt_seq_model.parameters(), lr = 1e-3)\n",
        "gpt_lr_sch = lr_scheduler.StepLR(gpt_optimizer, step_size=100, gamma=0.1)"
      ],
      "metadata": {
        "id": "gMnC2rUoUEAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty lists to store training and validation loss of each epoch\n",
        "gpt_train_losses = []\n",
        "# number of training epochs\n",
        "gpt_epochs = 10"
      ],
      "metadata": {
        "id": "0MKcYF_xUsma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start GPT model training\n",
        "for epoch in range(gpt_epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, gpt_epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train(gpt_seq_model, gpt_train_dataloader, gpt_optimizer, gpt_lr_sch)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    gpt_train_losses.append(train_loss)\n",
        "    # it can make your experiment reproducible, similar to set  random seed to all options where there needs a random seed.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "print(f'\\nTraining Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "id": "0X6B-sWmUvFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_response(\"Goodbye\", gpt_seq_model, gpt_tokenizer, gpt_max_seq_len)"
      ],
      "metadata": {
        "id": "iZo3_R9mc-z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a built-in pipepline that generate several squences of responses given one input."
      ],
      "metadata": {
        "id": "U8ShUJDir58k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)\n",
        "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n"
      ],
      "metadata": {
        "id": "nxng3BqSiWAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's take a look at how to manually implement a gpt-2 chatbot given several chatting rounds.\n",
        "\n",
        "Initialize a pretrained GPT-2 model using causal language modeling (CLM) objective. Under CLM, the idea is to predict the masked token in a given sentence, which is only allowed to consider words that occur to its left (unidirectional). CLM is suitable for text generation given its unidirectional nature."
      ],
      "metadata": {
        "id": "gGn0iFH0sInO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUHk8oHZ30_r"
      },
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "gpt_generate_model = AutoModelForCausalLM.from_pretrained('gpt2')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##One-round Conversation\n",
        "The basic idea is to aquire an input from user, encode the input and decode the response."
      ],
      "metadata": {
        "id": "ih6Keli2tp50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode user input and End-of-String (EOS) token\n",
        "user_input_ids = gpt_tokenizer.encode(input(\">> You:\") + gpt_tokenizer.eos_token, return_tensors='pt')\n",
        "print(user_input_ids)\n",
        "# Generate response given maximum chat length history of 50 tokens\n",
        "response_ids = gpt_generate_model.generate(user_input_ids, max_length=50, pad_token_id=gpt_tokenizer.eos_token_id)\n",
        "print(response_ids)\n",
        "# Print response, the response_ids will also contain the user_input_ids, we only need to print the chatbot resonse part\n",
        "print(\"GPT: {}\".format(gpt_tokenizer.decode(response_ids[0][user_input_ids.shape[-1]:], skip_special_tokens=True)))\n",
        "  \n"
      ],
      "metadata": {
        "id": "0o4f24lgmmSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DialoGPT\n",
        "DialoGPT adapts pretraining techniques to response generation using hundreds of Gigabytes of colloquial data.  Like GPT-2, DialoGPT is formulated as an autoregressive (AR) language model, and uses a multi-layer transformer as model architecture. Unlike GPT-2, which trains on general text data,  DialoGPT draws on 147M multi-turn dialogues extracted from Reddit discussion threads.\n"
      ],
      "metadata": {
        "id": "FYiyFcmRTARs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer and model\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "dialo_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "dialo_model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\")"
      ],
      "metadata": {
        "id": "jD101ImZzDXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Two-round Conversation\n",
        "To concatenate two rounds of conversations' chat history and generate a response."
      ],
      "metadata": {
        "id": "S-vHLg2_t9uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# conversation round\n",
        "chat_round = 2\n",
        "chat_history_ids = None\n",
        "# Encode user input and End-of-String (EOS) token\n",
        "user_input_ids = dialo_tokenizer.encode(input(\">> You:\") + dialo_tokenizer.eos_token, return_tensors='pt')\n",
        "# Generate response given maximum chat length history of 50 tokens\n",
        "chat_history_ids = dialo_model.generate(user_input_ids, max_length=50, pad_token_id=dialo_tokenizer.eos_token_id)\n",
        "# Print response, the response_ids will also contain the user_input_ids, we only need to print the chatbot resonse part\n",
        "print(\"DialoGPT: {}\".format(dialo_tokenizer.decode(chat_history_ids[:, user_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n",
        "\n",
        "# second round\n",
        "user_input_ids = dialo_tokenizer.encode(input(\">> You:\") + dialo_tokenizer.eos_token, return_tensors='pt')\n",
        "bot_input_ids = torch.cat([chat_history_ids, user_input_ids], dim=-1)\n",
        "chat_history_ids = dialo_model.generate(bot_input_ids, max_length=50, pad_token_id=dialo_tokenizer.eos_token_id)\n",
        "print(\"DialoGPT: {}\".format(dialo_tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n",
        "\n"
      ],
      "metadata": {
        "id": "U5jGWXGByyg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Your Turn!\n",
        "Now is your turn to try to build a n-round Conversation DialoGPT where n should be larger than 4."
      ],
      "metadata": {
        "id": "BejlX0rVSxPc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6zD5Scs5BD9"
      },
      "source": [
        "\n",
        "\n",
        "def generate_response(tokenizer, model, chat_round, chat_history_ids):\n",
        "  \"\"\"\n",
        "    Generate a response to some user input.\n",
        "  \"\"\"\n",
        "  # Encode user input and End-of-String (EOS) token\n",
        "  new_input_ids = \n",
        "\n",
        "  # Append tokens to chat history\n",
        "  bot_input_ids = \n",
        "\n",
        "  # Generate response given maximum chat length history of 1250 tokens\n",
        "  chat_history_ids = \n",
        "\n",
        "  # Print response\n",
        "  print()\n",
        "  \n",
        "  # Return the chat history ids\n",
        "  return chat_history_ids\n",
        "\n",
        "\n",
        "def chat_for_n_rounds(n=5):\n",
        "  \"\"\"\n",
        "  Chat with chatbot for n rounds (n = 5 by default)\n",
        "  \"\"\"\n",
        "  # Initialize history variable\n",
        "  chat_history_ids = None\n",
        "  \n",
        "  # Chat for n rounds\n",
        "  for chat_round in range(n):\n",
        "    chat_history_ids = \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls1npa6I5CY8"
      },
      "source": [
        "chat_for_n_rounds(5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}